{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "node1 = tf.constant(3.0, dtype=tf.float32)\n",
    "node2 = tf.constant(4.0) #also tf.float32 type implicitly\n",
    "print(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3: Tensor(\"Add:0\", shape=(), dtype=float32)\n",
      "sess.run(node3): 7.0\n"
     ]
    }
   ],
   "source": [
    "node3 = tf.add(node1, node2)\n",
    "print(\"node3:\", node3)\n",
    "print(\"sess.run(node3):\", sess.run(node3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(adder_node, {a:3, b:4.5}))\n",
    "print(sess.run(adder_node, {a: [1,3], b: [2, 4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.5\n"
     ]
    }
   ],
   "source": [
    "add_and_triple = adder_node * 3\n",
    "print(sess.run(add_and_triple, {a: 3, b: 4.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since X is a placeholder, we can evaluate linear_model for several values of x simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(linear_model, {x: [1,2,3,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is essentially the basics of running a linear model, but we don't know how good it performs until we compare it with y. So we need a  placeholder and develop a loss function linear_model - y. We call tf.square to square the error, then sum all the squared errors to create a single scalar that abstracts the error of all examples using tf.reduce_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss, {x: [1,2,3,4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cost can be optimized using operations like tf.assign. For example, W=-1 and b=1 are optimal parameters for this model, so changing them according"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x: [1,2,3,4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So hip hip hooray for us in finding the optimal values. But the point of machine learning is to train it so that it comes out with the optimal values it self. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.train API\n",
    "\n",
    "Tensorflow provides optimizers that slowly change each variable in order to minimize the loss function. The simplest optimization function is gradient descent. Tensorflow provides gradients with tf.gradients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sess.run(init) #resetting to incorrect defaults\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x: [1,2,3,4], y: [0, -1, -2, -3]})\n",
    "\n",
    "print(sess.run([W, b]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Program\n",
    "\n",
    "Complete trainable linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.99999952] b: [ 0.99999869] loss: 1.06581e-12\n"
     ]
    }
   ],
   "source": [
    "#Model parameters\n",
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "#Model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W*x+b\n",
    "y = tf.placeholder(tf.float32)\n",
    "#loss\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y)) #sum of the squares optimizer\n",
    "#optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.02)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "#training data\n",
    "x_train = [1,2,3,4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "#training loop\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init) #reset values to wrong\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x: x_train, y: y_train})\n",
    "    \n",
    "#evaluate training accuracy\n",
    "curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "print(\"W: %s b: %s loss: %s\" %(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.estimator\n",
    "tf.estimator is a high-level TensorFlow library that simplifies the mechanics of machine learning, including the following: \n",
    "\n",
    "-running training loops\n",
    "-running evaluation loops\n",
    "-managing data sets\n",
    "\n",
    "tf.estimator defines many common models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmppj1_7kzk\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmppj1_7kzk', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmppj1_7kzk/model.ckpt.\n",
      "INFO:tensorflow:loss = 23.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1731.12\n",
      "INFO:tensorflow:loss = 0.0939314, step = 101 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1612.62\n",
      "INFO:tensorflow:loss = 0.081118, step = 201 (0.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 1660.19\n",
      "INFO:tensorflow:loss = 0.0184602, step = 301 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1722.44\n",
      "INFO:tensorflow:loss = 0.00909807, step = 401 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1541.84\n",
      "INFO:tensorflow:loss = 0.00193905, step = 501 (0.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 1608.63\n",
      "INFO:tensorflow:loss = 0.000574944, step = 601 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1710.93\n",
      "INFO:tensorflow:loss = 0.000166709, step = 701 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1647.85\n",
      "INFO:tensorflow:loss = 5.15491e-05, step = 801 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1508.13\n",
      "INFO:tensorflow:loss = 1.98539e-05, step = 901 (0.066 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmppj1_7kzk/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.96091e-06.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-07-20:30:36\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmppj1_7kzk/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-07-20:30:37\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.45546e-06, global_step = 1000, loss = 5.82185e-06\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-07-20:30:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmppj1_7kzk/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-07-20:30:38\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.00262954, global_step = 1000, loss = 0.0105181\n",
      "train metrics: {'average_loss': 1.4554632e-06, 'loss': 5.8218529e-06, 'global_step': 1000}\n",
      "eval metrics: {'average_loss': 0.0026295367, 'loss': 0.010518147, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Declare list of features, we only have one numeric feature. There are many\n",
    "#other types of columns that are more complicated and useful.\n",
    "\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "#An estimator is the front end to invoke training (fitting)\n",
    "#and evaluation (inference.) There are many predefined\n",
    "#types like linear regression, linear classification,\n",
    "#and many neural networks classifiers and regressors\n",
    "#The following code provides an estimator that does\n",
    "#linear regression\n",
    "\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns = feature_columns)\n",
    "\n",
    "#Tensorflow provides many helper methods to read and\n",
    "#setup data sets. Here we use two data sets, one \n",
    "#for training and one for evaluation\n",
    "#We have to tell the function how many batches of data\n",
    "#(num_epochs) we want and how big each batch should be\n",
    "\n",
    "x_train = np.array([1., 2., 3., 4.,])\n",
    "y_train = np.array([0., -1., -2., -3.,])\n",
    "x_eval = np.array([2., 5., 8., 1.,])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None,\n",
    "    shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000\n",
    "    , shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000,\n",
    "    shuffle=False)\n",
    "\n",
    "#We can invoke 1000 training steps by invoking the\n",
    "#method and passing the training data set\n",
    "\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "#Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom model\n",
    "\n",
    "tf.estimator does not lock you into predefined models. Suppose we wanted to create a custom model that is not built into TensorFlow. We can still retain the high level abstraction of data set, feeding, training, etc. of tf.estimator. Implementing LinearRegressor using our knowledge of the lower level TensorFlow API\n",
    "\n",
    "To define a custom model that works with tf.estimator, we need to use tf.estimator.Estimator. tf.estimator.LinearRegressor is actually a sub-class of tf.estimator.Estimator. Instead of sub-classing Estimator, we simply provide Estimator a function model_fun that tells tf.estimator how ti can evaluate predictions, training steps, and loss. The code is as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp9woo6myd\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp9woo6myd', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp9woo6myd/model.ckpt.\n",
      "INFO:tensorflow:loss = 17.3073748566, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1864.28\n",
      "INFO:tensorflow:loss = 0.0192774576863, step = 101 (0.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 1703.56\n",
      "INFO:tensorflow:loss = 0.00288327237648, step = 201 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1814.26\n",
      "INFO:tensorflow:loss = 0.000230137170487, step = 301 (0.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 1691.05\n",
      "INFO:tensorflow:loss = 2.93158518164e-05, step = 401 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1774.65\n",
      "INFO:tensorflow:loss = 1.65322159928e-06, step = 501 (0.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 1653.27\n",
      "INFO:tensorflow:loss = 7.90992465767e-08, step = 601 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1668.41\n",
      "INFO:tensorflow:loss = 2.25354851284e-08, step = 701 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1680.09\n",
      "INFO:tensorflow:loss = 2.1410183839e-09, step = 801 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1776.04\n",
      "INFO:tensorflow:loss = 1.15047632411e-10, step = 901 (0.056 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp9woo6myd/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.715772771e-11.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-07-21:16:49\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9woo6myd/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-07-21:16:49\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.09503e-11\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-07-21:16:50\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9woo6myd/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-07-21:16:50\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0101004\n",
      "train metrics: {'loss': 1.0950347e-11, 'global_step': 1000}\n",
      "eval metrics: {'loss': 0.010100441, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "#Declare list of feature, we only have one real-valued features\n",
    "def model_fn(features, labels, mode):\n",
    "    #Build a linear model and predict values\n",
    "    W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "    b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "    y = W*features['x'] + b\n",
    "    #Loss sub-graph\n",
    "    loss = tf.reduce_sum(tf.square(labels-y))\n",
    "    #Training sub-graph\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = tf.group(optimizer.minimize(loss), tf.assign_add(global_step, 1))\n",
    "    \n",
    "    #EstimatorSpec connects subgraphs we built to the appropriate functionality\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=y,\n",
    "        loss = loss,\n",
    "        train_op = train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "#define our data sets\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.,])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "#train\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
